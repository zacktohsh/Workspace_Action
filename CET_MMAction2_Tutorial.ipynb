{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CET: MMAction2 Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ed4a075c7d34c79a241d705783c0c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f10e370fef54250b833ac690e4dd8d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45ac36307d2b41bb8e057b787c9e7618",
              "IPY_MODEL_b9ba1b1db83e4d9c8435c09bbac166ea"
            ]
          }
        },
        "7f10e370fef54250b833ac690e4dd8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45ac36307d2b41bb8e057b787c9e7618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_422e264747a54c0b850f6273a9d9d2f9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5d688af2eaa49e8a4afda49d8c7f914"
          }
        },
        "b9ba1b1db83e4d9c8435c09bbac166ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ce9f6b5af4144bea420eb2073e47006",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [02:29&lt;00:00, 685kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ebea6af2fc7413fa21f2b1b5393b08b"
          }
        },
        "422e264747a54c0b850f6273a9d9d2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5d688af2eaa49e8a4afda49d8c7f914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ce9f6b5af4144bea420eb2073e47006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ebea6af2fc7413fa21f2b1b5393b08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjSRFELVbNk"
      },
      "source": [
        "# MMAction2 Tutorial\n",
        "\n",
        "Welcome to MMAction2! This is the official colab tutorial for using MMAction2. In this tutorial, you will learn\n",
        "- Perform inference with a MMAction2 recognizer.\n",
        "- Train a new recognizer with a new dataset.\n",
        "\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LqHGkGEVqpm"
      },
      "source": [
        "## Install MMAction2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5jqB-opDU1r",
        "outputId": "6e5b337f-e247-4b8a-f50b-fd695e54918a"
      },
      "source": [
        "# Load the Drive helper and mount\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "# This will prompt for authorization.\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "# Change director listing to your google drive.\r\n",
        "% cd /content/drive/My Drive"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYxh_tXvKgju",
        "outputId": "5497859c-17dd-43af-cc30-1fbf2bc92094"
      },
      "source": [
        "# Execute this only once so that the repository is cloned into your \"Workspace\" folder.\r\n",
        "! git clone https://github.com/zacktohsh/Workspace_Action\r\n",
        "\r\n",
        "# Change director listing to your google drive.\r\n",
        "% cd /content/drive/My Drive/Workspace_Action\r\n",
        "\r\n",
        "#https://drive.google.com/file/d/1R3Be-PIy3ZeXNpKsGaQa7gR82wOLhHlZ/view?usp=sharing\r\n",
        "!gdown --id 1R3Be-PIy3ZeXNpKsGaQa7gR82wOLhHlZ\r\n",
        "\r\n",
        "!unzip -a Workspace_Action.zip\r\n",
        "!rm Workspace_Action.zip\r\n",
        "# Verify correct path and content downloaded\r\n",
        "! pwd\r\n",
        "! ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n",
            "Cloning into 'Workspace_Action'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 32 (delta 11), reused 17 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n",
            "/content/drive/My Drive/Workspace_Action\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R3Be-PIy3ZeXNpKsGaQa7gR82wOLhHlZ\n",
            "To: /content/drive/My Drive/Workspace_Action/Workspace_Action.zip\n",
            "886MB [00:10, 83.4MB/s]\n",
            "Archive:  Workspace_Action.zip\n",
            "   creating: mmaction2/\n",
            "   creating: mmaction2/.git/\n",
            "   creating: mmaction2/.github/\n",
            "  inflating: mmaction2/.github/CODE_OF_CONDUCT.md  [binary]\n",
            "  inflating: mmaction2/.github/CONTRIBUTING.md  [binary]\n",
            "   creating: mmaction2/.github/ISSUE_TEMPLATE/\n",
            "  inflating: mmaction2/.github/ISSUE_TEMPLATE/config.yml  [binary]\n",
            "  inflating: mmaction2/.github/ISSUE_TEMPLATE/error-report.md  [binary]\n",
            "  inflating: mmaction2/.github/ISSUE_TEMPLATE/feature_request.md  [binary]\n",
            "  inflating: mmaction2/.github/ISSUE_TEMPLATE/general_questions.md  [binary]\n",
            "  inflating: mmaction2/.github/ISSUE_TEMPLATE/reimplementation_questions.md  [binary]\n",
            "   creating: mmaction2/.github/workflows/\n",
            "  inflating: mmaction2/.github/workflows/build.yml  [binary]\n",
            "  inflating: mmaction2/.github/workflows/deploy.yml  [binary]\n",
            "  inflating: mmaction2/.gitignore    [binary]\n",
            "  inflating: mmaction2/.git/config   [binary]\n",
            "  inflating: mmaction2/.git/description  [binary]\n",
            "  inflating: mmaction2/.git/FETCH_HEAD  [binary]\n",
            " extracting: mmaction2/.git/HEAD     [binary]\n",
            "   creating: mmaction2/.git/hooks/\n",
            "  inflating: mmaction2/.git/hooks/applypatch-msg.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/commit-msg.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/fsmonitor-watchman.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/post-update.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/pre-applypatch.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/pre-commit.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/pre-merge-commit.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/pre-push.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/pre-rebase.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/pre-receive.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/prepare-commit-msg.sample  [binary]\n",
            "  inflating: mmaction2/.git/hooks/update.sample  [binary]\n",
            "  inflating: mmaction2/.git/index    [binary]\n",
            "   creating: mmaction2/.git/info/\n",
            "  inflating: mmaction2/.git/info/exclude  [binary]\n",
            "   creating: mmaction2/.git/logs/\n",
            "  inflating: mmaction2/.git/logs/HEAD  [binary]\n",
            "   creating: mmaction2/.git/logs/refs/\n",
            "   creating: mmaction2/.git/logs/refs/heads/\n",
            "  inflating: mmaction2/.git/logs/refs/heads/master  [binary]\n",
            "   creating: mmaction2/.git/logs/refs/remotes/\n",
            "   creating: mmaction2/.git/logs/refs/remotes/origin/\n",
            "  inflating: mmaction2/.git/logs/refs/remotes/origin/HEAD  [binary]\n",
            "  inflating: mmaction2/.git/logs/refs/remotes/origin/master  [binary]\n",
            "   creating: mmaction2/.git/objects/\n",
            "   creating: mmaction2/.git/objects/info/\n",
            "   creating: mmaction2/.git/objects/pack/\n",
            "  inflating: mmaction2/.git/objects/pack/pack-57be3fdace3fcd57b1f9a5bcbc3ddb2582e6893a.idx  [binary]\n",
            "  inflating: mmaction2/.git/objects/pack/pack-57be3fdace3fcd57b1f9a5bcbc3ddb2582e6893a.pack  [binary]\n",
            "  inflating: mmaction2/.git/objects/pack/pack-624d9b9eb1ba31b2baeb5aa170da0d2ae3e2aec2.idx  [binary]\n",
            "  inflating: mmaction2/.git/objects/pack/pack-624d9b9eb1ba31b2baeb5aa170da0d2ae3e2aec2.pack  [binary]\n",
            "  inflating: mmaction2/.git/packed-refs  [binary]\n",
            "   creating: mmaction2/.git/refs/\n",
            "   creating: mmaction2/.git/refs/heads/\n",
            " extracting: mmaction2/.git/refs/heads/master  [binary]\n",
            "   creating: mmaction2/.git/refs/remotes/\n",
            "   creating: mmaction2/.git/refs/remotes/origin/\n",
            " extracting: mmaction2/.git/refs/remotes/origin/HEAD  [binary]\n",
            " extracting: mmaction2/.git/refs/remotes/origin/master  [binary]\n",
            "   creating: mmaction2/.git/refs/tags/\n",
            "  inflating: mmaction2/.pre-commit-config.yaml  [binary]\n",
            "  inflating: mmaction2/.pylintrc     [binary]\n",
            "  inflating: mmaction2/.readthedocs.yml  [binary]\n",
            "   creating: mmaction2/checkpoints/\n",
            "  inflating: mmaction2/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth  [binary]\n",
            "   creating: mmaction2/configs/\n",
            "   creating: mmaction2/configs/localization/\n",
            "   creating: mmaction2/configs/localization/bmn/\n",
            "  inflating: mmaction2/configs/localization/bmn/bmn_400x100_2x8_9e_activitynet_feature.py  [binary]\n",
            "  inflating: mmaction2/configs/localization/bmn/README.md  [binary]\n",
            "   creating: mmaction2/configs/localization/bsn/\n",
            "  inflating: mmaction2/configs/localization/bsn/bsn_pem_400x100_1x16_20e_activitynet_feature.py  [binary]\n",
            "  inflating: mmaction2/configs/localization/bsn/bsn_pgm_400x100_activitynet_feature.py  [binary]\n",
            "  inflating: mmaction2/configs/localization/bsn/bsn_tem_400x100_1x16_20e_activitynet_feature.py  [binary]\n",
            "  inflating: mmaction2/configs/localization/bsn/README.md  [binary]\n",
            "   creating: mmaction2/configs/localization/ssn/\n",
            "  inflating: mmaction2/configs/localization/ssn/README.md  [binary]\n",
            "  inflating: mmaction2/configs/localization/ssn/ssn_r50_450e_thumos14_rgb_test.py  [binary]\n",
            "  inflating: mmaction2/configs/localization/ssn/ssn_r50_450e_thumos14_rgb_train.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/\n",
            "   creating: mmaction2/configs/recognition/c3d/\n",
            "  inflating: mmaction2/configs/recognition/c3d/c3d_sports1m_16x1x1_45e_ucf101_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/c3d/README.md  [binary]\n",
            "   creating: mmaction2/configs/recognition/csn/\n",
            "  inflating: mmaction2/configs/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/csn/README.md  [binary]\n",
            "   creating: mmaction2/configs/recognition/i3d/\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_nl_dot_product_r50_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_nl_gaussian_r50_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_dense_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_heavy_8x8x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_lazy_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_video_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_video_heavy_8x8x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/i3d_r50_video_inference_32x2x1_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/i3d/README.md  [binary]\n",
            "   creating: mmaction2/configs/recognition/omnisource/\n",
            "  inflating: mmaction2/configs/recognition/omnisource/pipeline.png  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/README.md  [binary]\n",
            "   creating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/\n",
            "  inflating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_googleimage_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_insvideo_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_kineticsraw_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_omnisource_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/slowonly_r50_8x8x1_256e_minikinetics/slowonly_r50_8x8x1_256e_minikinetics_webimage_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/\n",
            "  inflating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/tsn_r50_1x1x8_100e_minikinetics_googleimage_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/tsn_r50_1x1x8_100e_minikinetics_insvideo_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/tsn_r50_1x1x8_100e_minikinetics_kineticsraw_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/tsn_r50_1x1x8_100e_minikinetics_omnisource_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/tsn_r50_1x1x8_100e_minikinetics_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/omnisource/tsn_r50_1x1x8_100e_minikinetics/tsn_r50_1x1x8_100e_minikinetics_webimage_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/r2plus1d/\n",
            "  inflating: mmaction2/configs/recognition/r2plus1d/r2plus1d_r34_32x2x1_180e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/r2plus1d/r2plus1d_r34_8x8x1_180e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/r2plus1d/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/r2plus1d/r2plus1d_r34_video_inference_8x8x1_180e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/r2plus1d/README.md  [binary]\n",
            "   creating: mmaction2/configs/recognition/slowfast/\n",
            "  inflating: mmaction2/configs/recognition/slowfast/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowfast/slowfast_r50_8x8x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowfast/slowfast_r50_video_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowfast/slowfast_r50_video_inference_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/slowonly/\n",
            "   creating: mmaction2/configs/recognition/slowonly/data_benchmark/\n",
            "  inflating: mmaction2/configs/recognition/slowonly/data_benchmark/slowonly_r50_randomresizedcrop_256p_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/data_benchmark/slowonly_r50_randomresizedcrop_320p_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/data_benchmark/slowonly_r50_randomresizedcrop_340x256_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_imagenet_pretrained_r50_4x16x1_120e_gym99_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_imagenet_pretrained_r50_4x16x1_150e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_imagenet_pretrained_r50_8x8x1_150e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_kinetics_pretrained_r50_4x16x1_120e_gym99_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r101_8x8x1_196e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_4x16x1_256e_kinetics400_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_8x8x1_256e_kinetics400_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_8x8x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_video_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_video_8x8x1_256e_kinetics600_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_video_8x8x1_256e_kinetics700_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/slowonly/slowonly_r50_video_inference_4x16x1_256e_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/tin/\n",
            "  inflating: mmaction2/configs/recognition/tin/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tin/tin_r50_1x1x8_40e_sthv1_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tin/tin_r50_1x1x8_40e_sthv2_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tin/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/tpn/\n",
            "  inflating: mmaction2/configs/recognition/tpn/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tpn/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tpn/tpn_slowonly_r50_8x8x1_150e_kinetics_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tpn/tpn_tsm_r50_1x1x8_150e_sthv1_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/tsm/\n",
            "  inflating: mmaction2/configs/recognition/tsm/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_nl_dot_product_r50_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_nl_embedded_gaussian_r50_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_nl_gaussian_r50_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r101_1x1x8_50e_sthv1_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r101_1x1x8_50e_sthv2_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_1x1x16_50e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_1x1x16_50e_sthv1_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_1x1x16_50e_sthv2_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_1x1x8_50e_sthv1_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_1x1x8_50e_sthv2_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_dense_1x1x8_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_video_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_r50_video_inference_1x1x8_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsm/tsm_temporal_pool_r50_1x1x8_50e_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/tsn/\n",
            "   creating: mmaction2/configs/recognition/tsn/data_benchmark/\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_multiscalecrop_256p_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_multiscalecrop_320p_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_multiscalecrop_340x256_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_randomresizedcrop_256p_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_randomresizedcrop_320p_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_randomresizedcrop_340x256_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_test_256p_1x1x25_10crop_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_test_256p_1x1x25_3crop_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_test_320p_1x1x25_10crop_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_test_320p_1x1x25_3crop_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_test_340x256_1x1x25_10crop_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/data_benchmark/tsn_r50_test_340x256_1x1x25_3crop_100e_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/tsn/hvu/\n",
            "  inflating: mmaction2/configs/recognition/tsn/hvu/tsn_r18_1x1x8_100e_hvu_action_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/hvu/tsn_r18_1x1x8_100e_hvu_attribute_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/hvu/tsn_r18_1x1x8_100e_hvu_concept_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/hvu/tsn_r18_1x1x8_100e_hvu_event_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/hvu/tsn_r18_1x1x8_100e_hvu_object_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/hvu/tsn_r18_1x1x8_100e_hvu_scene_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_fp16_r50_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r101_1x1x5_50e_mmit_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x16_50e_sthv1_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x16_50e_sthv2_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x3_75e_ucf101_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x6_100e_mit_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x8_50e_hmdb51_imagenet_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x8_50e_hmdb51_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x8_50e_hmdb51_mit_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x8_50e_sthv1_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_1x1x8_50e_sthv2_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x3_110e_kinetics400_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x8_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x8_110e_kinetics400_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x8_150e_activitynet_clip_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x8_150e_activitynet_video_flow.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x8_50e_activitynet_clip_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_320p_1x1x8_50e_activitynet_video_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_dense_1x1x5_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_dense_1x1x8_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_inference_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics600_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics700_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_video_320p_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_video_dense_1x1x8_100e_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition/x3d/\n",
            "  inflating: mmaction2/configs/recognition/x3d/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition/x3d/x3d_m_16x5x1_facebook_kinetics400_rgb.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition/x3d/x3d_s_13x6x1_facebook_kinetics400_rgb.py  [binary]\n",
            "   creating: mmaction2/configs/recognition_audio/\n",
            "   creating: mmaction2/configs/recognition_audio/audioonly/\n",
            "  inflating: mmaction2/configs/recognition_audio/audioonly/audioonly_r50_64x1x1_100e_kinetics400_audio_feature.py  [binary]\n",
            "   creating: mmaction2/configs/recognition_audio/resnet/\n",
            "  inflating: mmaction2/configs/recognition_audio/resnet/README.md  [binary]\n",
            "  inflating: mmaction2/configs/recognition_audio/resnet/tsn_r18_64x1x1_100e_kinetics400_audio_feature.py  [binary]\n",
            "  inflating: mmaction2/configs/recognition_audio/resnet/tsn_r50_64x1x1_100e_kinetics400_audio.py  [binary]\n",
            "   creating: mmaction2/demo/\n",
            "  inflating: mmaction2/demo/demo.gif  [binary]\n",
            "  inflating: mmaction2/demo/demo.ipynb  [binary]\n",
            "  inflating: mmaction2/demo/demo.mp4  [binary]\n",
            "  inflating: mmaction2/demo/demo.py  [binary]\n",
            "  inflating: mmaction2/demo/demo_gradcam.gif  [binary]\n",
            "  inflating: mmaction2/demo/demo_gradcam.py  [binary]\n",
            "  inflating: mmaction2/demo/demo_out.mp4  [binary]\n",
            "   creating: mmaction2/demo/fuse/\n",
            "  inflating: mmaction2/demo/fuse/data_list.txt  [binary]\n",
            "  inflating: mmaction2/demo/fuse/flow.pkl  [binary]\n",
            "  inflating: mmaction2/demo/fuse/rgb.pkl  [binary]\n",
            "  inflating: mmaction2/demo/label_map.txt  [binary]\n",
            "  inflating: mmaction2/demo/long_video_demo.py  [binary]\n",
            "  inflating: mmaction2/demo/mmaction2_tutorial.ipynb  [binary]\n",
            "  inflating: mmaction2/demo/README.md  [binary]\n",
            "  inflating: mmaction2/demo/webcam_demo.py  [binary]\n",
            "   creating: mmaction2/docker/\n",
            "  inflating: mmaction2/docker/Dockerfile  [binary]\n",
            "   creating: mmaction2/docs/\n",
            "  inflating: mmaction2/docs/api.rst  [binary]\n",
            "  inflating: mmaction2/docs/benchmark.md  [binary]\n",
            "  inflating: mmaction2/docs/changelog.md  [binary]\n",
            "  inflating: mmaction2/docs/conf.py  [binary]\n",
            "  inflating: mmaction2/docs/config.md  [binary]\n",
            "  inflating: mmaction2/docs/data_preparation.md  [binary]\n",
            "  inflating: mmaction2/docs/faq.md   [binary]\n",
            "  inflating: mmaction2/docs/getting_started.md  [binary]\n",
            "   creating: mmaction2/docs/imgs/\n",
            "  inflating: mmaction2/docs/imgs/acc_curve.png  [binary]\n",
            "  inflating: mmaction2/docs/imgs/data_pipeline.png  [binary]\n",
            "  inflating: mmaction2/docs/imgs/mmaction2_logo.png  [binary]\n",
            "  inflating: mmaction2/docs/imgs/mmaction2_overview.gif  [binary]\n",
            "  inflating: mmaction2/docs/index.rst  [binary]\n",
            "  inflating: mmaction2/docs/install.md  [binary]\n",
            "  inflating: mmaction2/docs/make.bat  [binary]\n",
            "  inflating: mmaction2/docs/Makefile  [binary]\n",
            "  inflating: mmaction2/docs/merge_docs.sh  [binary]\n",
            "  inflating: mmaction2/docs/stat.py  [binary]\n",
            "  inflating: mmaction2/docs/supported_datasets.md  [binary]\n",
            "   creating: mmaction2/docs/tutorials/\n",
            "  inflating: mmaction2/docs/tutorials/customize_runtime.md  [binary]\n",
            "  inflating: mmaction2/docs/tutorials/data_pipeline.md  [binary]\n",
            "  inflating: mmaction2/docs/tutorials/export_model.md  [binary]\n",
            "  inflating: mmaction2/docs/tutorials/finetune.md  [binary]\n",
            "  inflating: mmaction2/docs/tutorials/new_dataset.md  [binary]\n",
            "  inflating: mmaction2/docs/tutorials/new_modules.md  [binary]\n",
            "  inflating: mmaction2/docs/useful_tools.md  [binary]\n",
            "   creating: mmaction2/kinetics400_tiny/\n",
            "  inflating: mmaction2/kinetics400_tiny/kinetics_tiny_train_video.txt  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/kinetics_tiny_val_video.txt  [binary]\n",
            "   creating: mmaction2/kinetics400_tiny/train/\n",
            "  inflating: mmaction2/kinetics400_tiny/train/27_CSXByd3s.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/34XczvTaRiI.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/A-wiliK50Zw.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/D32_1gwq35E.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/D92m0HsHjcQ.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/DbX8mPslRXg.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/FMlSTTpN3VY.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/h10B9SVE-nk.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/h2YqqUhnR34.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/iRuyZSKhHRg.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/IyfILH9lBRo.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/kFC3KY2bOP8.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/LvcFDgCAXQs.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/O46YA8tI530.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/oMrZaozOvdQ.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/oXy-e_P_cAI.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/P5M-hAts7MQ.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/phDqGd0NKoo.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/PnOe3GZRVX8.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/R8HXQkdgKWA.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/RqnKtCEoEcA.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/soEcZZsBmDs.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/TkkZPZHbAKA.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/T_TMNGzVrDk.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/WaS0qwP46Us.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/Wh_YPQdH1Zg.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/WWP5HZJsg-o.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/xGY2dP0YUjA.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/yLC9CtWU5ws.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/train/ZQV4U2KQ370.mp4  [binary]\n",
            "   creating: mmaction2/kinetics400_tiny/val/\n",
            "  inflating: mmaction2/kinetics400_tiny/val/0pVGiAU6XEA.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/AQrbRSnRt8M.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/b6Q_b7vgc7Q.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/ddvJ6-faICE.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/IcLztCtvhb8.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/ik4BW3-SCts.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/jqRrH30V0k4.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/SU_x2LQqSLs.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/u4Rm6srmIS8.mp4  [binary]\n",
            "  inflating: mmaction2/kinetics400_tiny/val/y5Iu7XkTqV0.mp4  [binary]\n",
            "  inflating: mmaction2/LICENSE       [binary]\n",
            "   creating: mmaction2/mmaction/\n",
            "   creating: mmaction2/mmaction/apis/\n",
            "  inflating: mmaction2/mmaction/apis/inference.py  [binary]\n",
            "  inflating: mmaction2/mmaction/apis/test.py  [binary]\n",
            "  inflating: mmaction2/mmaction/apis/train.py  [binary]\n",
            "  inflating: mmaction2/mmaction/apis/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/core/\n",
            "   creating: mmaction2/mmaction/core/evaluation/\n",
            "  inflating: mmaction2/mmaction/core/evaluation/accuracy.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/evaluation/eval_detection.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/evaluation/eval_hooks.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/evaluation/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/core/lr/\n",
            "  inflating: mmaction2/mmaction/core/lr/tin_lr_hook.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/lr/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/core/optimizer/\n",
            "  inflating: mmaction2/mmaction/core/optimizer/copy_of_sgd.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/optimizer/tsm_optimizer_constructor.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/optimizer/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/core/runner/\n",
            "  inflating: mmaction2/mmaction/core/runner/omnisource_runner.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/runner/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/core/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/datasets/\n",
            "  inflating: mmaction2/mmaction/datasets/activitynet_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/audio_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/audio_feature_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/audio_visual_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/ava_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/base.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/builder.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/dataset_wrappers.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/hvu_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/image_dataset.py  [binary]\n",
            "   creating: mmaction2/mmaction/datasets/pipelines/\n",
            "  inflating: mmaction2/mmaction/datasets/pipelines/augmentations.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/pipelines/compose.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/pipelines/formating.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/pipelines/loading.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/pipelines/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/rawframe_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/rawvideo_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/registry.py  [binary]\n",
            "   creating: mmaction2/mmaction/datasets/samplers/\n",
            "  inflating: mmaction2/mmaction/datasets/samplers/distributed_sampler.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/samplers/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/ssn_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/video_dataset.py  [binary]\n",
            "  inflating: mmaction2/mmaction/datasets/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/localization/\n",
            "  inflating: mmaction2/mmaction/localization/bsn_utils.py  [binary]\n",
            "  inflating: mmaction2/mmaction/localization/proposal_utils.py  [binary]\n",
            "  inflating: mmaction2/mmaction/localization/ssn_utils.py  [binary]\n",
            "  inflating: mmaction2/mmaction/localization/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/\n",
            "   creating: mmaction2/mmaction/models/backbones/\n",
            "  inflating: mmaction2/mmaction/models/backbones/c3d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet2plus1d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet3d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet3d_csn.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet3d_slowfast.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet3d_slowonly.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet_audio.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet_tin.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/resnet_tsm.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/x3d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/backbones/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/builder.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/common/\n",
            "  inflating: mmaction2/mmaction/models/common/conv2plus1d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/common/conv_audio.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/common/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/heads/\n",
            "  inflating: mmaction2/mmaction/models/heads/audio_tsn_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/base.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/i3d_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/slowfast_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/ssn_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/tpn_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/tsm_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/tsn_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/x3d_head.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/heads/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/localizers/\n",
            "  inflating: mmaction2/mmaction/models/localizers/base.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/localizers/bmn.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/localizers/bsn.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/localizers/ssn.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/localizers/utils/\n",
            "  inflating: mmaction2/mmaction/models/localizers/utils/post_processing.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/localizers/utils/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/localizers/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/losses/\n",
            "  inflating: mmaction2/mmaction/models/losses/base.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/binary_logistic_regression_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/bmn_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/cross_entropy_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/hvu_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/nll_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/ohem_hinge_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/ssn_loss.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/losses/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/necks/\n",
            "  inflating: mmaction2/mmaction/models/necks/tpn.py  [binary]\n",
            " extracting: mmaction2/mmaction/models/necks/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/models/recognizers/\n",
            "  inflating: mmaction2/mmaction/models/recognizers/audio_recognizer.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/recognizers/base.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/recognizers/recognizer2d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/recognizers/recognizer3d.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/recognizers/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/registry.py  [binary]\n",
            "  inflating: mmaction2/mmaction/models/__init__.py  [binary]\n",
            "   creating: mmaction2/mmaction/utils/\n",
            "  inflating: mmaction2/mmaction/utils/collect_env.py  [binary]\n",
            "  inflating: mmaction2/mmaction/utils/gradcam_utils.py  [binary]\n",
            "  inflating: mmaction2/mmaction/utils/logger.py  [binary]\n",
            "  inflating: mmaction2/mmaction/utils/misc.py  [binary]\n",
            "  inflating: mmaction2/mmaction/utils/__init__.py  [binary]\n",
            "  inflating: mmaction2/mmaction/version.py  [binary]\n",
            "  inflating: mmaction2/mmaction/__init__.py  [binary]\n",
            "  inflating: mmaction2/README.md     [binary]\n",
            "   creating: mmaction2/requirements/\n",
            "  inflating: mmaction2/requirements.txt  [binary]\n",
            " extracting: mmaction2/requirements/build.txt  [binary]\n",
            "  inflating: mmaction2/requirements/docs.txt  [binary]\n",
            " extracting: mmaction2/requirements/optional.txt  [binary]\n",
            " extracting: mmaction2/requirements/readthedocs.txt  [binary]\n",
            " extracting: mmaction2/requirements/runtime.txt  [binary]\n",
            "  inflating: mmaction2/requirements/tests.txt  [binary]\n",
            "  inflating: mmaction2/setup.cfg     [binary]\n",
            "  inflating: mmaction2/setup.py      [binary]\n",
            "   creating: mmaction2/tests/\n",
            "   creating: mmaction2/tests/data/\n",
            "  inflating: mmaction2/tests/data/action_test_anno.json  [binary]\n",
            " extracting: mmaction2/tests/data/audio_feature_test_list.txt  [binary]\n",
            "  inflating: mmaction2/tests/data/audio_test_list.txt  [binary]\n",
            " extracting: mmaction2/tests/data/frame_test_list.txt  [binary]\n",
            " extracting: mmaction2/tests/data/frame_test_list_multi_label.txt  [binary]\n",
            " extracting: mmaction2/tests/data/frame_test_list_with_offset.txt  [binary]\n",
            "  inflating: mmaction2/tests/data/hvu_frame_test_anno.json  [binary]\n",
            "  inflating: mmaction2/tests/data/hvu_video_eval_test_anno.json  [binary]\n",
            "  inflating: mmaction2/tests/data/hvu_video_test_anno.json  [binary]\n",
            "  inflating: mmaction2/tests/data/proposal_normalized_list.txt  [binary]\n",
            "  inflating: mmaction2/tests/data/proposal_test_list.txt  [binary]\n",
            "  inflating: mmaction2/tests/data/rawvideo_test_anno.json  [binary]\n",
            " extracting: mmaction2/tests/data/rawvideo_test_anno.txt  [binary]\n",
            "  inflating: mmaction2/tests/data/test.avi  [binary]\n",
            "  inflating: mmaction2/tests/data/test.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test.mp4  [binary]\n",
            "  inflating: mmaction2/tests/data/test.wav  [binary]\n",
            "   creating: mmaction2/tests/data/test_activitynet_features/\n",
            "  inflating: mmaction2/tests/data/test_activitynet_features/v_test1.csv  [binary]\n",
            "  inflating: mmaction2/tests/data/test_activitynet_features/v_test2.csv  [binary]\n",
            "   creating: mmaction2/tests/data/test_ava_dataset/\n",
            " extracting: mmaction2/tests/data/test_ava_dataset/ava_excluded_timestamps_sample.csv  [binary]\n",
            "  inflating: mmaction2/tests/data/test_ava_dataset/ava_proposals_sample.pkl  [binary]\n",
            "  inflating: mmaction2/tests/data/test_ava_dataset/ava_sample.csv  [binary]\n",
            "   creating: mmaction2/tests/data/test_bsp_features/\n",
            "  inflating: mmaction2/tests/data/test_bsp_features/v_test1.npy  [binary]\n",
            "   creating: mmaction2/tests/data/test_eval_detection/\n",
            "  inflating: mmaction2/tests/data/test_eval_detection/gt.json  [binary]\n",
            "  inflating: mmaction2/tests/data/test_eval_detection/result.json  [binary]\n",
            "   creating: mmaction2/tests/data/test_imgs/\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00001.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00002.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00003.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00004.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00005.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00006.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00007.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00008.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00009.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/img_00010.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/x_00001.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/x_00002.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/x_00003.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/x_00004.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/x_00005.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/y_00001.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/y_00002.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/y_00003.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/y_00004.jpg  [binary]\n",
            "  inflating: mmaction2/tests/data/test_imgs/y_00005.jpg  [binary]\n",
            "   creating: mmaction2/tests/data/test_proposals/\n",
            "  inflating: mmaction2/tests/data/test_proposals/v_test1.csv  [binary]\n",
            "  inflating: mmaction2/tests/data/test_proposals/v_test2.csv  [binary]\n",
            "   creating: mmaction2/tests/data/test_rawvideo_dataset/\n",
            "  inflating: mmaction2/tests/data/test_rawvideo_dataset/part_0.mp4  [binary]\n",
            "  inflating: mmaction2/tests/data/test_rawvideo_dataset/part_1.mp4  [binary]\n",
            "   creating: mmaction2/tests/data/test_tem_results/\n",
            "  inflating: mmaction2/tests/data/test_tem_results/v_test1.csv  [binary]\n",
            "  inflating: mmaction2/tests/data/test_tem_results/v_test2.csv  [binary]\n",
            " extracting: mmaction2/tests/data/video_test_list.txt  [binary]\n",
            "  inflating: mmaction2/tests/test_accuracy.py  [binary]\n",
            "   creating: mmaction2/tests/test_data/\n",
            "  inflating: mmaction2/tests/test_data/test_augmentations.py  [binary]\n",
            "  inflating: mmaction2/tests/test_data/test_ava_dataset.py  [binary]\n",
            "  inflating: mmaction2/tests/test_data/test_compose.py  [binary]\n",
            "  inflating: mmaction2/tests/test_data/test_dataset.py  [binary]\n",
            "  inflating: mmaction2/tests/test_data/test_formating.py  [binary]\n",
            "  inflating: mmaction2/tests/test_data/test_loading.py  [binary]\n",
            "  inflating: mmaction2/tests/test_gradcam.py  [binary]\n",
            "  inflating: mmaction2/tests/test_localization_utils.py  [binary]\n",
            "  inflating: mmaction2/tests/test_loss.py  [binary]\n",
            "   creating: mmaction2/tests/test_models/\n",
            "  inflating: mmaction2/tests/test_models/test_backbone.py  [binary]\n",
            "  inflating: mmaction2/tests/test_models/test_common_modules.py  [binary]\n",
            "  inflating: mmaction2/tests/test_models/test_head.py  [binary]\n",
            "  inflating: mmaction2/tests/test_models/test_inference.py  [binary]\n",
            "  inflating: mmaction2/tests/test_models/test_localizers.py  [binary]\n",
            "  inflating: mmaction2/tests/test_models/test_neck.py  [binary]\n",
            "  inflating: mmaction2/tests/test_models/test_recognizers.py  [binary]\n",
            "   creating: mmaction2/tests/test_runtime/\n",
            "  inflating: mmaction2/tests/test_runtime/test_apis_test.py  [binary]\n",
            "  inflating: mmaction2/tests/test_runtime/test_config.py  [binary]\n",
            "  inflating: mmaction2/tests/test_runtime/test_eval_hook.py  [binary]\n",
            "  inflating: mmaction2/tests/test_runtime/test_lr.py  [binary]\n",
            "  inflating: mmaction2/tests/test_runtime/test_onnx.py  [binary]\n",
            "  inflating: mmaction2/tests/test_runtime/test_optimizer.py  [binary]\n",
            "  inflating: mmaction2/tests/test_runtime/test_train.py  [binary]\n",
            "   creating: mmaction2/tools/\n",
            "   creating: mmaction2/tools/analysis/\n",
            "  inflating: mmaction2/tools/analysis/analyze_logs.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/benchmark.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/bench_processing.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/eval_metric.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/get_flops.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/print_config.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/report_accuracy.py  [binary]\n",
            "  inflating: mmaction2/tools/analysis/report_map.py  [binary]\n",
            "  inflating: mmaction2/tools/argparse.bash  [binary]\n",
            "  inflating: mmaction2/tools/bsn_proposal_generation.py  [binary]\n",
            "   creating: mmaction2/tools/data/\n",
            "   creating: mmaction2/tools/data/activitynet/\n",
            "  inflating: mmaction2/tools/data/activitynet/action_name.csv  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/activitynet_feature_postprocessing.py  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/convert_proposal_format.py  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/download.py  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/download_features.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/environment.yml  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/generate_rawframes_filelist.py  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/process_annotations.py  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/README.md  [binary]\n",
            "  inflating: mmaction2/tools/data/activitynet/tsn_feature_extraction.py  [binary]\n",
            "  inflating: mmaction2/tools/data/anno_txt2json.py  [binary]\n",
            "   creating: mmaction2/tools/data/ava/\n",
            "  inflating: mmaction2/tools/data/ava/cut_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/download_videos_gnu_parallel.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/download_videos_parallel.py  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/download_videos_parallel.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/extract_rgb_frames_ffmpeg.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/fetch_ava_proposals.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ava/README.md  [binary]\n",
            "  inflating: mmaction2/tools/data/build_audio_features.py  [binary]\n",
            "  inflating: mmaction2/tools/data/build_file_list.py  [binary]\n",
            "  inflating: mmaction2/tools/data/build_rawframes.py  [binary]\n",
            "  inflating: mmaction2/tools/data/build_videos.py  [binary]\n",
            "  inflating: mmaction2/tools/data/denormalize_proposal_file.py  [binary]\n",
            "  inflating: mmaction2/tools/data/extract_audio.py  [binary]\n",
            "   creating: mmaction2/tools/data/gym/\n",
            "  inflating: mmaction2/tools/data/gym/download.py  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/environment.yml  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/generate_file_list.py  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/README.md  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/trim_event.py  [binary]\n",
            "  inflating: mmaction2/tools/data/gym/trim_subaction.py  [binary]\n",
            "   creating: mmaction2/tools/data/hmdb51/\n",
            "  inflating: mmaction2/tools/data/hmdb51/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hmdb51/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/hvu/\n",
            "  inflating: mmaction2/tools/data/hvu/download.py  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/environment.yml  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/generate_file_list.py  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/generate_sub_file_list.py  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/parse_tag_list.py  [binary]\n",
            "  inflating: mmaction2/tools/data/hvu/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/jester/\n",
            "  inflating: mmaction2/tools/data/jester/encode_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/jester/extract_flow.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/jester/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/jester/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/jester/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/jhmdb/\n",
            "  inflating: mmaction2/tools/data/jhmdb/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/kinetics/\n",
            "  inflating: mmaction2/tools/data/kinetics/download.py  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/environment.yml  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/README.md  [binary]\n",
            "  inflating: mmaction2/tools/data/kinetics/rename_classnames.sh  [binary]\n",
            "   creating: mmaction2/tools/data/mit/\n",
            "  inflating: mmaction2/tools/data/mit/download_data.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mit/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mit/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mit/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mit/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mit/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mit/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/mmit/\n",
            "  inflating: mmaction2/tools/data/mmit/download_data.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mmit/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mmit/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mmit/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mmit/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mmit/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/mmit/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/omnisource/\n",
            "  inflating: mmaction2/tools/data/omnisource/README.md  [binary]\n",
            "  inflating: mmaction2/tools/data/omnisource/trim_raw_video.py  [binary]\n",
            "  inflating: mmaction2/tools/data/parse_file_list.py  [binary]\n",
            "  inflating: mmaction2/tools/data/resize_video.py  [binary]\n",
            "   creating: mmaction2/tools/data/sthv1/\n",
            "  inflating: mmaction2/tools/data/sthv1/encode_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv1/extract_flow.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv1/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv1/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv1/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/sthv2/\n",
            "  inflating: mmaction2/tools/data/sthv2/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv2/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv2/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv2/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv2/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/sthv2/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/thumos14/\n",
            "  inflating: mmaction2/tools/data/thumos14/denormalize_proposal_file.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/fetch_tag_proposals.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/thumos14/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/ucf101/\n",
            "  inflating: mmaction2/tools/data/ucf101/download_annotations.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/download_videos.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/extract_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/extract_rgb_frames.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/extract_rgb_frames_opencv.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/generate_rawframes_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/generate_videos_filelist.sh  [binary]\n",
            "  inflating: mmaction2/tools/data/ucf101/README.md  [binary]\n",
            "   creating: mmaction2/tools/data/ucf101_24/\n",
            "  inflating: mmaction2/tools/data/ucf101_24/README.md  [binary]\n",
            "  inflating: mmaction2/tools/dist_test.sh  [binary]\n",
            "  inflating: mmaction2/tools/dist_train.sh  [binary]\n",
            "  inflating: mmaction2/tools/flow_extraction.py  [binary]\n",
            "  inflating: mmaction2/tools/publish_model.py  [binary]\n",
            "  inflating: mmaction2/tools/pytorch2onnx.py  [binary]\n",
            "  inflating: mmaction2/tools/slurm_test.sh  [binary]\n",
            "  inflating: mmaction2/tools/slurm_train  [binary]\n",
            "  inflating: mmaction2/tools/slurm_train.sh  [binary]\n",
            "  inflating: mmaction2/tools/test.py  [binary]\n",
            "  inflating: mmaction2/tools/train.py  [binary]\n",
            " extracting: mmaction2/tools/__init__.py  [empty] \n",
            "  inflating: mmcv_full-latest+torch1.5.0+cu101-cp36-cp36m-manylinux1_x86_64.whl  [binary]\n",
            "  inflating: torch-1.5.1+cu101-cp36-cp36m-linux_x86_64.whl  [binary]\n",
            "  inflating: torchvision-0.6.1+cu101-cp36-cp36m-linux_x86_64.whl  [binary]\n",
            "/content/drive/My Drive/Workspace_Action\n",
            "total 717454\n",
            "drwx------ 14 root root      4096 Dec 22  2020 mmaction2\n",
            "-rw-------  1 root root  23647323 Dec 22  2020 mmcv_full-latest+torch1.5.0+cu101-cp36-cp36m-manylinux1_x86_64.whl\n",
            "-rw-------  1 root root       307 Dec 22 04:50 README.md\n",
            "-rw-------  1 root root 704382372 Dec 22  2020 torch-1.5.1+cu101-cp36-cp36m-linux_x86_64.whl\n",
            "-rw-------  1 root root   6637481 Dec 22  2020 torchvision-0.6.1+cu101-cp36-cp36m-linux_x86_64.whl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf8PpPXtVvmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0768d3-27e2-4107-e156-3b77a23bfcab"
      },
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version\n",
        "\n",
        "# Check python version\n",
        "!python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFE9On1w3JNF",
        "outputId": "691cf22d-c0e6-4680-ffce-da8bccfa097a"
      },
      "source": [
        "#Installation of required libraries and files.\r\n",
        "!pip install torch-1.5.1+cu101-cp36-cp36m-linux_x86_64.whl\r\n",
        "!pip install torchvision-0.6.1+cu101-cp36-cp36m-linux_x86_64.whl\r\n",
        "!pip install mmcv_full-latest+torch1.5.0+cu101-cp36-cp36m-manylinux1_x86_64.whl\r\n",
        "\r\n",
        "%cd mmaction2\r\n",
        "!pip install -e .\r\n",
        "\r\n",
        "# Install some optional requirements\r\n",
        "!pip install -r requirements/optional.txt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./torch-1.5.1+cu101-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.19.4)\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu101\n",
            "Processing ./torchvision-0.6.1+cu101-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (1.19.4)\n",
            "Requirement already satisfied: torch==1.5.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (1.5.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1->torchvision==0.6.1+cu101) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torchvision-0.6.1+cu101\n",
            "Processing ./mmcv_full-latest+torch1.5.0+cu101-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv-full==latest+torch1.5.0+cu101) (1.19.4)\n",
            "Collecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl\n",
            "Collecting yapf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/5d/d84677fe852bc5e091739acda444a9b6700ffc6b11a21b00dd244c8caef0/yapf-0.30.0-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 16.0MB/s \n",
            "\u001b[?25hInstalling collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.2.1 yapf-0.30.0\n",
            "/content/drive/My Drive/Workspace_Action/mmaction2\n",
            "Obtaining file:///content/drive/My%20Drive/Workspace_Action/mmaction2\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.9.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.9.0) (1.19.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.9.0) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mmaction2==0.9.0) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.9.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.9.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.9.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmaction2==0.9.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->mmaction2==0.9.0) (1.15.0)\n",
            "Installing collected packages: mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "Successfully installed mmaction2\n",
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/62/9a992be76f8e13ce0e3a24a838191b546805545116f9fc869bd11bd21b5f/av-8.0.2-cp36-cp36m-manylinux2010_x86_64.whl (36.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36.9MB 87kB/s \n",
            "\u001b[?25hCollecting decord>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/0c/7d99cfcde7b85f80c9ea9b0b19441339ad3cef59ee7fa5386598db714efe/decord-0.4.2-py2.py3-none-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.8MB 57.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from -r requirements/optional.txt (line 3)) (0.2.3.5)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/82/e8d0fb64df623a3b716145192ed50604f444889778b37e0e9262753d5046/onnx-1.8.0-cp36-cp36m-manylinux2010_x86_64.whl (7.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.7MB 40.4MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/f009251fd1b91a2e1ce6f22d4b5be9936fbd0072842c5087a2a49706c509/onnxruntime-1.6.0-cp36-cp36m-manylinux2014_x86_64.whl (4.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.1MB 55.6MB/s \n",
            "\u001b[?25hCollecting PyTurboJPEG\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/f5/6106c673096b1bc1af716bbc9b17e542c77ccad5fafd150afb91ff18a6e8/PyTurboJPEG-1.4.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from decord>=0.4.1->-r requirements/optional.txt (line 2)) (1.19.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->-r requirements/optional.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->-r requirements/optional.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->-r requirements/optional.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx->-r requirements/optional.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx->-r requirements/optional.txt (line 4)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->-r requirements/optional.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy->-r requirements/optional.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx->-r requirements/optional.txt (line 4)) (50.3.2)\n",
            "Building wheels for collected packages: PyTurboJPEG\n",
            "  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.4.1-cp36-none-any.whl size=7003 sha256=5809464e0c0d9a1580887426b01e2ac939b5a029425d4fceaf99b3a8a910c6f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/21/97/152eed6e60d59f1c432139dee7a2e89de44026ef1855b4c4d7\n",
            "Successfully built PyTurboJPEG\n",
            "Installing collected packages: av, decord, onnx, onnxruntime, PyTurboJPEG\n",
            "Successfully installed PyTurboJPEG-1.4.1 av-8.0.2 decord-0.4.2 onnx-1.8.0 onnxruntime-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No_zZAFpWC-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f384a33-d274-4f58-8d22-9aaeaeb5f931"
      },
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101 True\n",
            "0.9.0\n",
            "10.1\n",
            "GCC 7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf7oV5DWdab"
      },
      "source": [
        "## Perform inference with a MMAction2 recognizer\n",
        "MMAction2 already provides high level APIs to do inference and training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pkL5XXWEXp8"
      },
      "source": [
        "#!mkdir checkpoints\r\n",
        "#!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\r\n",
        "#      -O checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNZB7NoSabzj"
      },
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = 'configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEMsBnpHapAn"
      },
      "source": [
        "# Use the recognizer to do inference\n",
        "video = 'demo/demo.mp4'\n",
        "label = 'demo/label_map.txt'\n",
        "results = inference_recognizer(model, video, label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIyJXqfWathq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeffd946-9e7b-4433-df29-60e763ee3031"
      },
      "source": [
        "# Let's show the results\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arm wrestling:  1.0\n",
            "rock scissors paper:  6.4344654e-09\n",
            "shaking hands:  2.7599913e-09\n",
            "clapping:  1.3454664e-09\n",
            "massaging feet:  5.555122e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuZG8kZ2fJ5d"
      },
      "source": [
        "## Train a recognizer on customized dataset\n",
        "\n",
        "To train a new recognizer, there are usually three things to do:\n",
        "1. Support a new dataset\n",
        "2. Modify the config\n",
        "3. Train a new recognizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEFyxChfgiJ"
      },
      "source": [
        "### Support a new dataset\n",
        "\n",
        "In this tutorial, we gives an example to convert the data into the format of existing datasets. Other methods and more advanced usages can be found in the [doc](/docs/tutorials/new_dataset.md)\n",
        "\n",
        "Firstly, let's download a tiny dataset obtained from [Kinetics-400](https://deepmind.com/research/open-source/open-source-datasets/kinetics/). We select 30 videos with their labels as train dataset and 10 videos with their labels as test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf-zRDGLFoeE"
      },
      "source": [
        "# download, decompress the data\r\n",
        "#!rm kinetics400_tiny.zip*\r\n",
        "#!rm -rf kinetics400_tiny\r\n",
        "#!wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\r\n",
        "#!unzip kinetics400_tiny.zip > /dev/null"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbZ-o7V6hNw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40650f18-6b02-415e-dc01-dc9d340b4c6a"
      },
      "source": [
        "# Check the directory structure of the tiny data\n",
        "\n",
        "# Install tree first\n",
        "!apt-get -q install tree\n",
        "!tree kinetics400_tiny"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "tree is already the newest version (1.7.0-5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "kinetics400_tiny\n",
            "â”œâ”€â”€ kinetics_tiny_train_video.txt\n",
            "â”œâ”€â”€ kinetics_tiny_val_video.txt\n",
            "â”œâ”€â”€ train\n",
            "â”‚Â Â  â”œâ”€â”€ 27_CSXByd3s.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ 34XczvTaRiI.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ A-wiliK50Zw.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ D32_1gwq35E.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ D92m0HsHjcQ.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ DbX8mPslRXg.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ FMlSTTpN3VY.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ h10B9SVE-nk.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ h2YqqUhnR34.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ iRuyZSKhHRg.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ IyfILH9lBRo.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ kFC3KY2bOP8.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ LvcFDgCAXQs.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ O46YA8tI530.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ oMrZaozOvdQ.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ oXy-e_P_cAI.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ P5M-hAts7MQ.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ phDqGd0NKoo.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ PnOe3GZRVX8.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ R8HXQkdgKWA.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ RqnKtCEoEcA.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ soEcZZsBmDs.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ TkkZPZHbAKA.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ T_TMNGzVrDk.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ WaS0qwP46Us.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ Wh_YPQdH1Zg.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ WWP5HZJsg-o.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ xGY2dP0YUjA.mp4\n",
            "â”‚Â Â  â”œâ”€â”€ yLC9CtWU5ws.mp4\n",
            "â”‚Â Â  â””â”€â”€ ZQV4U2KQ370.mp4\n",
            "â””â”€â”€ val\n",
            "    â”œâ”€â”€ 0pVGiAU6XEA.mp4\n",
            "    â”œâ”€â”€ AQrbRSnRt8M.mp4\n",
            "    â”œâ”€â”€ b6Q_b7vgc7Q.mp4\n",
            "    â”œâ”€â”€ ddvJ6-faICE.mp4\n",
            "    â”œâ”€â”€ IcLztCtvhb8.mp4\n",
            "    â”œâ”€â”€ ik4BW3-SCts.mp4\n",
            "    â”œâ”€â”€ jqRrH30V0k4.mp4\n",
            "    â”œâ”€â”€ SU_x2LQqSLs.mp4\n",
            "    â”œâ”€â”€ u4Rm6srmIS8.mp4\n",
            "    â””â”€â”€ y5Iu7XkTqV0.mp4\n",
            "\n",
            "2 directories, 42 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTdi6dI0hY3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de69c657-c214-49f5-c7ba-f9b78af44607"
      },
      "source": [
        "# After downloading the data, we need to check the annotation format\n",
        "!cat kinetics400_tiny/kinetics_tiny_train_video.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D32_1gwq35E.mp4 0\n",
            "iRuyZSKhHRg.mp4 1\n",
            "oXy-e_P_cAI.mp4 0\n",
            "34XczvTaRiI.mp4 1\n",
            "h2YqqUhnR34.mp4 0\n",
            "O46YA8tI530.mp4 0\n",
            "kFC3KY2bOP8.mp4 1\n",
            "WWP5HZJsg-o.mp4 1\n",
            "phDqGd0NKoo.mp4 1\n",
            "yLC9CtWU5ws.mp4 0\n",
            "27_CSXByd3s.mp4 1\n",
            "IyfILH9lBRo.mp4 1\n",
            "T_TMNGzVrDk.mp4 1\n",
            "TkkZPZHbAKA.mp4 0\n",
            "PnOe3GZRVX8.mp4 1\n",
            "soEcZZsBmDs.mp4 1\n",
            "FMlSTTpN3VY.mp4 1\n",
            "WaS0qwP46Us.mp4 0\n",
            "A-wiliK50Zw.mp4 1\n",
            "oMrZaozOvdQ.mp4 1\n",
            "ZQV4U2KQ370.mp4 0\n",
            "DbX8mPslRXg.mp4 1\n",
            "h10B9SVE-nk.mp4 1\n",
            "P5M-hAts7MQ.mp4 0\n",
            "R8HXQkdgKWA.mp4 0\n",
            "D92m0HsHjcQ.mp4 0\n",
            "RqnKtCEoEcA.mp4 0\n",
            "LvcFDgCAXQs.mp4 0\n",
            "xGY2dP0YUjA.mp4 0\n",
            "Wh_YPQdH1Zg.mp4 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bq0mxmEi29H"
      },
      "source": [
        "According to the format defined in [`VideoDataset`](./datasets/video_dataset.py), each line indicates a sample video with the filepath and label, which are split with a whitespace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a recognizer using a pre-trained recognizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjCcmCKOjktc"
      },
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('./configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8YhFFGjp3e"
      },
      "source": [
        "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on Kinetics400-tiny dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhu9byjjt-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9e80d6-7aac-438c-f74c-e1d323107c1d"
      },
      "source": [
        "from mmcv.runner import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'VideoDataset'\n",
        "cfg.data_root = 'kinetics400_tiny/train/'\n",
        "cfg.data_root_val = 'kinetics400_tiny/val/'\n",
        "cfg.ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.ann_file_test = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "\n",
        "cfg.data.test.type = 'VideoDataset'\n",
        "cfg.data.test.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.data.test.data_prefix = 'kinetics400_tiny/val/'\n",
        "\n",
        "cfg.data.train.type = 'VideoDataset'\n",
        "cfg.data.train.ann_file = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.data.train.data_prefix = 'kinetics400_tiny/train/'\n",
        "\n",
        "cfg.data.val.type = 'VideoDataset'\n",
        "cfg.data.val.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.data.val.data_prefix = 'kinetics400_tiny/val/'\n",
        "\n",
        "# The flag is used to determine whether it is omnisource training\n",
        "cfg.setdefault('omnisource', False)\n",
        "# Modify num classes of the model in cls_head\n",
        "cfg.model.cls_head.num_classes = 2\n",
        "# We can use the pre-trained TSN model\n",
        "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.data.videos_per_gpu = cfg.data.videos_per_gpu // 16\n",
        "cfg.optimizer.lr = cfg.optimizer.lr / 8 / 16\n",
        "cfg.total_epochs = 30\n",
        "\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 10\n",
        "# We can set the log print interval to reduce the the times of printing log\n",
        "cfg.log_config.interval = 5\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='torchvision://resnet50',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=2,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01))\n",
            "train_cfg = None\n",
            "test_cfg = dict(average_clips=None)\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "ann_file_test = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(1, 0.875, 0.75, 0.66),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='Flip', flip_ratio=0),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='ThreeCrop', crop_size=256),\n",
            "    dict(type='Flip', flip_ratio=0),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_bgr=False),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "    dict(type='ToTensor', keys=['imgs'])\n",
            "]\n",
            "data = dict(\n",
            "    videos_per_gpu=2,\n",
            "    workers_per_gpu=4,\n",
            "    train=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix='kinetics400_tiny/train/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=8),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(1, 0.875, 0.75, 0.66),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix='kinetics400_tiny/val/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='Flip', flip_ratio=0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix='kinetics400_tiny/val/',\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='ThreeCrop', crop_size=256),\n",
            "            dict(type='Flip', flip_ratio=0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_bgr=False),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
            "            dict(type='ToTensor', keys=['imgs'])\n",
            "        ]))\n",
            "optimizer = dict(type='SGD', lr=7.8125e-05, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
            "lr_config = dict(policy='step', step=[40, 80])\n",
            "total_epochs = 30\n",
            "checkpoint_config = dict(interval=10)\n",
            "evaluation = dict(\n",
            "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
            "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './tutorial_exps'\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "omnisource = False\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "### Train a new recognizer\n",
        "\n",
        "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDBWkdDRk6oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ed4a075c7d34c79a241d705783c0c2d",
            "7f10e370fef54250b833ac690e4dd8d9",
            "45ac36307d2b41bb8e057b787c9e7618",
            "b9ba1b1db83e4d9c8435c09bbac166ea",
            "422e264747a54c0b850f6273a9d9d2f9",
            "d5d688af2eaa49e8a4afda49d8c7f914",
            "1ce9f6b5af4144bea420eb2073e47006",
            "8ebea6af2fc7413fa21f2b1b5393b08b"
          ]
        },
        "outputId": "8ee18f1a-f069-4eae-da70-29d4f29554ac"
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmaction.datasets import build_dataset\n",
        "from mmaction.models import build_model\n",
        "from mmaction.apis import train_model\n",
        "\n",
        "import mmcv\n",
        "\n",
        "# Build the dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the recognizer\n",
        "model = build_model(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_model(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ed4a075c7d34c79a241d705783c0c2d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 04:57:29,633 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 04:57:29,699 - mmaction - INFO - load checkpoint from ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "2020-12-22 04:57:29,880 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "2020-12-22 04:57:29,883 - mmaction - INFO - Start running, host: root@daa45c12bfe6, work_dir: /content/drive/My Drive/Workspace_Action/mmaction2/tutorial_exps\n",
            "2020-12-22 04:57:29,884 - mmaction - INFO - workflow: [('train', 1)], max: 30 epochs\n",
            "2020-12-22 04:57:34,514 - mmaction - INFO - Epoch [1][5/15]\tlr: 7.813e-05, eta: 0:06:51, time: 0.924, data_time: 0.685, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6865, loss: 0.6865, grad_norm: 12.7663\n",
            "2020-12-22 04:57:35,512 - mmaction - INFO - Epoch [1][10/15]\tlr: 7.813e-05, eta: 0:04:07, time: 0.200, data_time: 0.004, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.7171, loss: 0.7171, grad_norm: 13.7446\n",
            "2020-12-22 04:57:36,419 - mmaction - INFO - Epoch [1][15/15]\tlr: 7.813e-05, eta: 0:03:09, time: 0.182, data_time: 0.009, memory: 2918, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 0.8884, loss: 0.8884, grad_norm: 14.7140\n",
            "2020-12-22 04:57:41,059 - mmaction - INFO - Epoch [2][5/15]\tlr: 7.813e-05, eta: 0:03:57, time: 0.906, data_time: 0.691, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6562, loss: 0.6562, grad_norm: 10.5716\n",
            "2020-12-22 04:57:42,463 - mmaction - INFO - Epoch [2][10/15]\tlr: 7.813e-05, eta: 0:03:31, time: 0.281, data_time: 0.087, memory: 2918, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 0.7480, loss: 0.7480, grad_norm: 11.7084\n",
            "2020-12-22 04:57:43,312 - mmaction - INFO - Epoch [2][15/15]\tlr: 7.813e-05, eta: 0:03:06, time: 0.170, data_time: 0.001, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6735, loss: 0.6735, grad_norm: 12.8064\n",
            "2020-12-22 04:57:47,984 - mmaction - INFO - Epoch [3][5/15]\tlr: 7.813e-05, eta: 0:03:31, time: 0.910, data_time: 0.641, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7218, loss: 0.7218, grad_norm: 12.4891\n",
            "2020-12-22 04:57:49,286 - mmaction - INFO - Epoch [3][10/15]\tlr: 7.813e-05, eta: 0:03:16, time: 0.263, data_time: 0.060, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6188, loss: 0.6188, grad_norm: 11.8113\n",
            "2020-12-22 04:57:50,144 - mmaction - INFO - Epoch [3][15/15]\tlr: 7.813e-05, eta: 0:03:00, time: 0.172, data_time: 0.002, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7298, loss: 0.7298, grad_norm: 12.5042\n",
            "2020-12-22 04:57:54,728 - mmaction - INFO - Epoch [4][5/15]\tlr: 7.813e-05, eta: 0:03:16, time: 0.894, data_time: 0.677, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6833, loss: 0.6833, grad_norm: 10.1039\n",
            "2020-12-22 04:57:55,935 - mmaction - INFO - Epoch [4][10/15]\tlr: 7.813e-05, eta: 0:03:04, time: 0.241, data_time: 0.042, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6640, loss: 0.6640, grad_norm: 11.7604\n",
            "2020-12-22 04:57:56,787 - mmaction - INFO - Epoch [4][15/15]\tlr: 7.813e-05, eta: 0:02:52, time: 0.171, data_time: 0.003, memory: 2918, top1_acc: 0.3000, top5_acc: 1.0000, loss_cls: 0.7373, loss: 0.7373, grad_norm: 13.6209\n",
            "2020-12-22 04:58:01,322 - mmaction - INFO - Epoch [5][5/15]\tlr: 7.813e-05, eta: 0:03:03, time: 0.887, data_time: 0.654, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6309, loss: 0.6309, grad_norm: 11.1862\n",
            "2020-12-22 04:58:02,314 - mmaction - INFO - Epoch [5][10/15]\tlr: 7.813e-05, eta: 0:02:53, time: 0.197, data_time: 0.004, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7178, loss: 0.7178, grad_norm: 12.4359\n",
            "2020-12-22 04:58:03,271 - mmaction - INFO - Epoch [5][15/15]\tlr: 7.813e-05, eta: 0:02:44, time: 0.193, data_time: 0.020, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7094, loss: 0.7094, grad_norm: 12.4632\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.0 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 04:58:05,481 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2020-12-22 04:58:05,486 - mmaction - INFO - \n",
            "top1_acc\t0.7000\n",
            "top5_acc\t1.0000\n",
            "2020-12-22 04:58:05,486 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2020-12-22 04:58:05,488 - mmaction - INFO - \n",
            "mean_acc\t0.7000\n",
            "2020-12-22 04:58:05,489 - mmaction - INFO - Now best checkpoint is epoch_5.pth\n",
            "2020-12-22 04:58:05,498 - mmaction - INFO - Epoch(val) [5][15]\ttop1_acc: 0.7000, top5_acc: 1.0000, mean_class_accuracy: 0.7000\n",
            "2020-12-22 04:58:10,292 - mmaction - INFO - Epoch [6][5/15]\tlr: 7.813e-05, eta: 0:02:54, time: 0.954, data_time: 0.729, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6696, loss: 0.6696, grad_norm: 11.0199\n",
            "2020-12-22 04:58:11,236 - mmaction - INFO - Epoch [6][10/15]\tlr: 7.813e-05, eta: 0:02:46, time: 0.189, data_time: 0.002, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6824, loss: 0.6824, grad_norm: 11.8895\n",
            "2020-12-22 04:58:12,098 - mmaction - INFO - Epoch [6][15/15]\tlr: 7.813e-05, eta: 0:02:38, time: 0.172, data_time: 0.002, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6869, loss: 0.6869, grad_norm: 13.7293\n",
            "2020-12-22 04:58:16,644 - mmaction - INFO - Epoch [7][5/15]\tlr: 7.813e-05, eta: 0:02:44, time: 0.888, data_time: 0.649, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6459, loss: 0.6459, grad_norm: 10.8083\n",
            "2020-12-22 04:58:17,745 - mmaction - INFO - Epoch [7][10/15]\tlr: 7.813e-05, eta: 0:02:37, time: 0.220, data_time: 0.006, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.6004, loss: 0.6004, grad_norm: 9.5408\n",
            "2020-12-22 04:58:18,807 - mmaction - INFO - Epoch [7][15/15]\tlr: 7.813e-05, eta: 0:02:31, time: 0.212, data_time: 0.042, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6828, loss: 0.6828, grad_norm: 12.0928\n",
            "2020-12-22 04:58:23,292 - mmaction - INFO - Epoch [8][5/15]\tlr: 7.813e-05, eta: 0:02:36, time: 0.875, data_time: 0.645, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6921, loss: 0.6921, grad_norm: 13.1961\n",
            "2020-12-22 04:58:24,577 - mmaction - INFO - Epoch [8][10/15]\tlr: 7.813e-05, eta: 0:02:30, time: 0.257, data_time: 0.030, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6074, loss: 0.6074, grad_norm: 11.3632\n",
            "2020-12-22 04:58:25,461 - mmaction - INFO - Epoch [8][15/15]\tlr: 7.813e-05, eta: 0:02:24, time: 0.177, data_time: 0.003, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7029, loss: 0.7029, grad_norm: 12.4477\n",
            "2020-12-22 04:58:29,919 - mmaction - INFO - Epoch [9][5/15]\tlr: 7.813e-05, eta: 0:02:28, time: 0.869, data_time: 0.642, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.5368, loss: 0.5368, grad_norm: 8.4105\n",
            "2020-12-22 04:58:31,266 - mmaction - INFO - Epoch [9][10/15]\tlr: 7.813e-05, eta: 0:02:23, time: 0.269, data_time: 0.068, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6797, loss: 0.6797, grad_norm: 12.8053\n",
            "2020-12-22 04:58:32,129 - mmaction - INFO - Epoch [9][15/15]\tlr: 7.813e-05, eta: 0:02:18, time: 0.172, data_time: 0.002, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5711, loss: 0.5711, grad_norm: 9.9661\n",
            "2020-12-22 04:58:36,570 - mmaction - INFO - Epoch [10][5/15]\tlr: 7.813e-05, eta: 0:02:20, time: 0.868, data_time: 0.641, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5379, loss: 0.5379, grad_norm: 8.8828\n",
            "2020-12-22 04:58:37,917 - mmaction - INFO - Epoch [10][10/15]\tlr: 7.813e-05, eta: 0:02:16, time: 0.269, data_time: 0.062, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.6643, loss: 0.6643, grad_norm: 12.6156\n",
            "2020-12-22 04:58:38,770 - mmaction - INFO - Epoch [10][15/15]\tlr: 7.813e-05, eta: 0:02:11, time: 0.170, data_time: 0.002, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.7041, loss: 0.7041, grad_norm: 12.4891\n",
            "2020-12-22 04:58:38,873 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 4.8 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 04:58:41,753 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2020-12-22 04:58:41,754 - mmaction - INFO - \n",
            "top1_acc\t0.9000\n",
            "top5_acc\t1.0000\n",
            "2020-12-22 04:58:41,757 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2020-12-22 04:58:41,760 - mmaction - INFO - \n",
            "mean_acc\t0.9000\n",
            "2020-12-22 04:58:41,761 - mmaction - INFO - Now best checkpoint is epoch_10.pth\n",
            "2020-12-22 04:58:41,768 - mmaction - INFO - Epoch(val) [10][15]\ttop1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000\n",
            "2020-12-22 04:58:46,146 - mmaction - INFO - Epoch [11][5/15]\tlr: 7.813e-05, eta: 0:02:13, time: 0.874, data_time: 0.636, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5357, loss: 0.5357, grad_norm: 8.8030\n",
            "2020-12-22 04:58:47,738 - mmaction - INFO - Epoch [11][10/15]\tlr: 7.813e-05, eta: 0:02:09, time: 0.319, data_time: 0.111, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5830, loss: 0.5830, grad_norm: 10.5931\n",
            "2020-12-22 04:58:48,602 - mmaction - INFO - Epoch [11][15/15]\tlr: 7.813e-05, eta: 0:02:05, time: 0.173, data_time: 0.002, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6231, loss: 0.6231, grad_norm: 11.3663\n",
            "2020-12-22 04:58:53,048 - mmaction - INFO - Epoch [12][5/15]\tlr: 7.813e-05, eta: 0:02:06, time: 0.868, data_time: 0.640, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5701, loss: 0.5701, grad_norm: 10.0648\n",
            "2020-12-22 04:58:54,212 - mmaction - INFO - Epoch [12][10/15]\tlr: 7.813e-05, eta: 0:02:02, time: 0.232, data_time: 0.035, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5980, loss: 0.5980, grad_norm: 11.1695\n",
            "2020-12-22 04:58:55,104 - mmaction - INFO - Epoch [12][15/15]\tlr: 7.813e-05, eta: 0:01:58, time: 0.179, data_time: 0.003, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6105, loss: 0.6105, grad_norm: 11.8507\n",
            "2020-12-22 04:58:59,477 - mmaction - INFO - Epoch [13][5/15]\tlr: 7.813e-05, eta: 0:01:59, time: 0.855, data_time: 0.644, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5438, loss: 0.5438, grad_norm: 10.4089\n",
            "2020-12-22 04:59:00,612 - mmaction - INFO - Epoch [13][10/15]\tlr: 7.813e-05, eta: 0:01:55, time: 0.227, data_time: 0.005, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6337, loss: 0.6337, grad_norm: 11.3853\n",
            "2020-12-22 04:59:01,581 - mmaction - INFO - Epoch [13][15/15]\tlr: 7.813e-05, eta: 0:01:51, time: 0.194, data_time: 0.016, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6328, loss: 0.6328, grad_norm: 12.0637\n",
            "2020-12-22 04:59:06,019 - mmaction - INFO - Epoch [14][5/15]\tlr: 7.813e-05, eta: 0:01:52, time: 0.866, data_time: 0.653, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6514, loss: 0.6514, grad_norm: 12.4948\n",
            "2020-12-22 04:59:07,309 - mmaction - INFO - Epoch [14][10/15]\tlr: 7.813e-05, eta: 0:01:48, time: 0.259, data_time: 0.073, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5537, loss: 0.5537, grad_norm: 10.6008\n",
            "2020-12-22 04:59:08,173 - mmaction - INFO - Epoch [14][15/15]\tlr: 7.813e-05, eta: 0:01:44, time: 0.173, data_time: 0.002, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.7073, loss: 0.7073, grad_norm: 12.8190\n",
            "2020-12-22 04:59:12,914 - mmaction - INFO - Epoch [15][5/15]\tlr: 7.813e-05, eta: 0:01:45, time: 0.927, data_time: 0.717, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6580, loss: 0.6580, grad_norm: 12.7101\n",
            "2020-12-22 04:59:13,927 - mmaction - INFO - Epoch [15][10/15]\tlr: 7.813e-05, eta: 0:01:41, time: 0.203, data_time: 0.006, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4524, loss: 0.4524, grad_norm: 8.1130\n",
            "2020-12-22 04:59:14,831 - mmaction - INFO - Epoch [15][15/15]\tlr: 7.813e-05, eta: 0:01:38, time: 0.181, data_time: 0.006, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6320, loss: 0.6320, grad_norm: 11.7258\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 4.9 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 04:59:17,064 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2020-12-22 04:59:17,066 - mmaction - INFO - \n",
            "top1_acc\t0.8000\n",
            "top5_acc\t1.0000\n",
            "2020-12-22 04:59:17,068 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2020-12-22 04:59:17,071 - mmaction - INFO - \n",
            "mean_acc\t0.8000\n",
            "2020-12-22 04:59:17,071 - mmaction - INFO - Epoch(val) [15][15]\ttop1_acc: 0.8000, top5_acc: 1.0000, mean_class_accuracy: 0.8000\n",
            "2020-12-22 04:59:21,321 - mmaction - INFO - Epoch [16][5/15]\tlr: 7.813e-05, eta: 0:01:38, time: 0.847, data_time: 0.613, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5428, loss: 0.5428, grad_norm: 10.0089\n",
            "2020-12-22 04:59:22,505 - mmaction - INFO - Epoch [16][10/15]\tlr: 7.813e-05, eta: 0:01:34, time: 0.238, data_time: 0.037, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6095, loss: 0.6095, grad_norm: 11.1777\n",
            "2020-12-22 04:59:23,439 - mmaction - INFO - Epoch [16][15/15]\tlr: 7.813e-05, eta: 0:01:31, time: 0.187, data_time: 0.006, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5309, loss: 0.5309, grad_norm: 9.9069\n",
            "2020-12-22 04:59:27,767 - mmaction - INFO - Epoch [17][5/15]\tlr: 7.813e-05, eta: 0:01:31, time: 0.844, data_time: 0.604, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6307, loss: 0.6307, grad_norm: 12.2806\n",
            "2020-12-22 04:59:29,194 - mmaction - INFO - Epoch [17][10/15]\tlr: 7.813e-05, eta: 0:01:28, time: 0.285, data_time: 0.083, memory: 2918, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 0.6635, loss: 0.6635, grad_norm: 13.0176\n",
            "2020-12-22 04:59:30,078 - mmaction - INFO - Epoch [17][15/15]\tlr: 7.813e-05, eta: 0:01:25, time: 0.177, data_time: 0.002, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.4259, loss: 0.4259, grad_norm: 8.0239\n",
            "2020-12-22 04:59:34,457 - mmaction - INFO - Epoch [18][5/15]\tlr: 7.813e-05, eta: 0:01:24, time: 0.856, data_time: 0.637, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5795, loss: 0.5795, grad_norm: 11.0254\n",
            "2020-12-22 04:59:35,886 - mmaction - INFO - Epoch [18][10/15]\tlr: 7.813e-05, eta: 0:01:21, time: 0.286, data_time: 0.085, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4537, loss: 0.4537, grad_norm: 8.3307\n",
            "2020-12-22 04:59:36,757 - mmaction - INFO - Epoch [18][15/15]\tlr: 7.813e-05, eta: 0:01:18, time: 0.174, data_time: 0.002, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4951, loss: 0.4951, grad_norm: 9.5790\n",
            "2020-12-22 04:59:41,340 - mmaction - INFO - Epoch [19][5/15]\tlr: 7.813e-05, eta: 0:01:17, time: 0.896, data_time: 0.653, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.5532, loss: 0.5532, grad_norm: 10.2652\n",
            "2020-12-22 04:59:42,701 - mmaction - INFO - Epoch [19][10/15]\tlr: 7.813e-05, eta: 0:01:15, time: 0.272, data_time: 0.060, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6117, loss: 0.6117, grad_norm: 11.5421\n",
            "2020-12-22 04:59:43,569 - mmaction - INFO - Epoch [19][15/15]\tlr: 7.813e-05, eta: 0:01:12, time: 0.173, data_time: 0.002, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4127, loss: 0.4127, grad_norm: 7.5744\n",
            "2020-12-22 04:59:48,114 - mmaction - INFO - Epoch [20][5/15]\tlr: 7.813e-05, eta: 0:01:11, time: 0.886, data_time: 0.669, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4327, loss: 0.4327, grad_norm: 8.4845\n",
            "2020-12-22 04:59:49,511 - mmaction - INFO - Epoch [20][10/15]\tlr: 7.813e-05, eta: 0:01:08, time: 0.280, data_time: 0.079, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4622, loss: 0.4622, grad_norm: 8.9815\n",
            "2020-12-22 04:59:50,384 - mmaction - INFO - Epoch [20][15/15]\tlr: 7.813e-05, eta: 0:01:05, time: 0.174, data_time: 0.002, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5918, loss: 0.5918, grad_norm: 11.3914\n",
            "2020-12-22 04:59:50,482 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 4.9 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 04:59:53,346 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2020-12-22 04:59:53,350 - mmaction - INFO - \n",
            "top1_acc\t0.9000\n",
            "top5_acc\t1.0000\n",
            "2020-12-22 04:59:53,351 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2020-12-22 04:59:53,353 - mmaction - INFO - \n",
            "mean_acc\t0.9000\n",
            "2020-12-22 04:59:53,355 - mmaction - INFO - Epoch(val) [20][15]\ttop1_acc: 0.9000, top5_acc: 1.0000, mean_class_accuracy: 0.9000\n",
            "2020-12-22 04:59:57,503 - mmaction - INFO - Epoch [21][5/15]\tlr: 7.813e-05, eta: 0:01:04, time: 0.828, data_time: 0.603, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4515, loss: 0.4515, grad_norm: 8.3872\n",
            "2020-12-22 04:59:59,020 - mmaction - INFO - Epoch [21][10/15]\tlr: 7.813e-05, eta: 0:01:01, time: 0.304, data_time: 0.078, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4542, loss: 0.4542, grad_norm: 9.0976\n",
            "2020-12-22 04:59:59,925 - mmaction - INFO - Epoch [21][15/15]\tlr: 7.813e-05, eta: 0:00:59, time: 0.181, data_time: 0.002, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5325, loss: 0.5325, grad_norm: 10.6029\n",
            "2020-12-22 05:00:04,577 - mmaction - INFO - Epoch [22][5/15]\tlr: 7.813e-05, eta: 0:00:57, time: 0.910, data_time: 0.660, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5645, loss: 0.5645, grad_norm: 10.7962\n",
            "2020-12-22 05:00:05,902 - mmaction - INFO - Epoch [22][10/15]\tlr: 7.813e-05, eta: 0:00:55, time: 0.265, data_time: 0.036, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5059, loss: 0.5059, grad_norm: 9.9767\n",
            "2020-12-22 05:00:06,835 - mmaction - INFO - Epoch [22][15/15]\tlr: 7.813e-05, eta: 0:00:52, time: 0.187, data_time: 0.012, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4390, loss: 0.4390, grad_norm: 8.7559\n",
            "2020-12-22 05:00:11,368 - mmaction - INFO - Epoch [23][5/15]\tlr: 7.813e-05, eta: 0:00:51, time: 0.885, data_time: 0.654, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.6279, loss: 0.6279, grad_norm: 12.5593\n",
            "2020-12-22 05:00:12,502 - mmaction - INFO - Epoch [23][10/15]\tlr: 7.813e-05, eta: 0:00:48, time: 0.227, data_time: 0.015, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.3282, loss: 0.3282, grad_norm: 6.4791\n",
            "2020-12-22 05:00:13,455 - mmaction - INFO - Epoch [23][15/15]\tlr: 7.813e-05, eta: 0:00:46, time: 0.190, data_time: 0.009, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4970, loss: 0.4970, grad_norm: 9.2455\n",
            "2020-12-22 05:00:18,074 - mmaction - INFO - Epoch [24][5/15]\tlr: 7.813e-05, eta: 0:00:44, time: 0.903, data_time: 0.665, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3842, loss: 0.3842, grad_norm: 7.6703\n",
            "2020-12-22 05:00:19,134 - mmaction - INFO - Epoch [24][10/15]\tlr: 7.813e-05, eta: 0:00:41, time: 0.212, data_time: 0.004, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5473, loss: 0.5473, grad_norm: 11.7914\n",
            "2020-12-22 05:00:20,092 - mmaction - INFO - Epoch [24][15/15]\tlr: 7.813e-05, eta: 0:00:39, time: 0.192, data_time: 0.003, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3737, loss: 0.3737, grad_norm: 7.4690\n",
            "2020-12-22 05:00:24,425 - mmaction - INFO - Epoch [25][5/15]\tlr: 7.813e-05, eta: 0:00:37, time: 0.844, data_time: 0.616, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5821, loss: 0.5821, grad_norm: 11.9577\n",
            "2020-12-22 05:00:25,725 - mmaction - INFO - Epoch [25][10/15]\tlr: 7.813e-05, eta: 0:00:35, time: 0.260, data_time: 0.040, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5972, loss: 0.5972, grad_norm: 11.7718\n",
            "2020-12-22 05:00:26,672 - mmaction - INFO - Epoch [25][15/15]\tlr: 7.813e-05, eta: 0:00:32, time: 0.189, data_time: 0.004, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4511, loss: 0.4511, grad_norm: 9.3104\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 5.0 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 05:00:28,877 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2020-12-22 05:00:28,879 - mmaction - INFO - \n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "2020-12-22 05:00:28,880 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2020-12-22 05:00:28,885 - mmaction - INFO - \n",
            "mean_acc\t1.0000\n",
            "2020-12-22 05:00:28,887 - mmaction - INFO - Now best checkpoint is epoch_25.pth\n",
            "2020-12-22 05:00:28,893 - mmaction - INFO - Epoch(val) [25][15]\ttop1_acc: 1.0000, top5_acc: 1.0000, mean_class_accuracy: 1.0000\n",
            "2020-12-22 05:00:33,616 - mmaction - INFO - Epoch [26][5/15]\tlr: 7.813e-05, eta: 0:00:31, time: 0.943, data_time: 0.731, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3755, loss: 0.3755, grad_norm: 7.9569\n",
            "2020-12-22 05:00:34,727 - mmaction - INFO - Epoch [26][10/15]\tlr: 7.813e-05, eta: 0:00:28, time: 0.222, data_time: 0.031, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5395, loss: 0.5395, grad_norm: 10.7605\n",
            "2020-12-22 05:00:35,610 - mmaction - INFO - Epoch [26][15/15]\tlr: 7.813e-05, eta: 0:00:26, time: 0.177, data_time: 0.001, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.4193, loss: 0.4193, grad_norm: 8.5507\n",
            "2020-12-22 05:00:40,115 - mmaction - INFO - Epoch [27][5/15]\tlr: 7.813e-05, eta: 0:00:24, time: 0.878, data_time: 0.644, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.5920, loss: 0.5920, grad_norm: 11.3933\n",
            "2020-12-22 05:00:41,134 - mmaction - INFO - Epoch [27][10/15]\tlr: 7.813e-05, eta: 0:00:22, time: 0.204, data_time: 0.004, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.4480, loss: 0.4480, grad_norm: 9.5198\n",
            "2020-12-22 05:00:42,193 - mmaction - INFO - Epoch [27][15/15]\tlr: 7.813e-05, eta: 0:00:19, time: 0.211, data_time: 0.032, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3868, loss: 0.3868, grad_norm: 8.2100\n",
            "2020-12-22 05:00:46,562 - mmaction - INFO - Epoch [28][5/15]\tlr: 7.813e-05, eta: 0:00:17, time: 0.852, data_time: 0.619, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5438, loss: 0.5438, grad_norm: 11.1993\n",
            "2020-12-22 05:00:47,581 - mmaction - INFO - Epoch [28][10/15]\tlr: 7.813e-05, eta: 0:00:15, time: 0.205, data_time: 0.004, memory: 2918, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4845, loss: 0.4845, grad_norm: 9.9178\n",
            "2020-12-22 05:00:48,559 - mmaction - INFO - Epoch [28][15/15]\tlr: 7.813e-05, eta: 0:00:13, time: 0.196, data_time: 0.005, memory: 2918, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3129, loss: 0.3129, grad_norm: 6.3262\n",
            "2020-12-22 05:00:53,178 - mmaction - INFO - Epoch [29][5/15]\tlr: 7.813e-05, eta: 0:00:11, time: 0.903, data_time: 0.677, memory: 2918, top1_acc: 1.0000, top5_acc: 1.0000, loss_cls: 0.3145, loss: 0.3145, grad_norm: 6.6591\n",
            "2020-12-22 05:00:54,252 - mmaction - INFO - Epoch [29][10/15]\tlr: 7.813e-05, eta: 0:00:08, time: 0.215, data_time: 0.003, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.4967, loss: 0.4967, grad_norm: 10.3029\n",
            "2020-12-22 05:00:55,180 - mmaction - INFO - Epoch [29][15/15]\tlr: 7.813e-05, eta: 0:00:06, time: 0.185, data_time: 0.008, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.5300, loss: 0.5300, grad_norm: 10.5814\n",
            "2020-12-22 05:00:59,646 - mmaction - INFO - Epoch [30][5/15]\tlr: 7.813e-05, eta: 0:00:04, time: 0.872, data_time: 0.635, memory: 2918, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 0.6775, loss: 0.6775, grad_norm: 13.5692\n",
            "2020-12-22 05:01:00,861 - mmaction - INFO - Epoch [30][10/15]\tlr: 7.813e-05, eta: 0:00:02, time: 0.243, data_time: 0.033, memory: 2918, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6275, loss: 0.6275, grad_norm: 12.5722\n",
            "2020-12-22 05:01:01,834 - mmaction - INFO - Epoch [30][15/15]\tlr: 7.813e-05, eta: 0:00:00, time: 0.194, data_time: 0.013, memory: 2918, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.5680, loss: 0.5680, grad_norm: 11.7022\n",
            "2020-12-22 05:01:01,937 - mmaction - INFO - Saving checkpoint at 30 epochs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 4.9 task/s, elapsed: 2s, ETA:     0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-22 05:01:05,254 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
            "2020-12-22 05:01:05,256 - mmaction - INFO - \n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "2020-12-22 05:01:05,257 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
            "2020-12-22 05:01:05,261 - mmaction - INFO - \n",
            "mean_acc\t1.0000\n",
            "2020-12-22 05:01:05,261 - mmaction - INFO - Epoch(val) [30][15]\ttop1_acc: 1.0000, top5_acc: 1.0000, mean_class_accuracy: 1.0000\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSd7oTLlxIf"
      },
      "source": [
        "### Understand the log\n",
        "From the log, we can have a basic understanding the training process and know how well the recognizer is trained.\n",
        "\n",
        "Firstly, the ResNet-50 backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost. The log shows that all the weights of the ResNet-50 backbone are loaded except the `fc.bias` and `fc.weight`.\n",
        "\n",
        "Second, since the dataset we are using is small, we loaded a TSN model and finetune it for action recognition.\n",
        "The original TSN is trained on original Kinetics-400 dataset which contains 400 classes but Kinetics-400 Tiny dataset only have 2 classes. Therefore, the last FC layer of the pre-trained TSN for classification has different weight shape and is not used.\n",
        "\n",
        "Third, after training, the recognizer is evaluated by the default evaluation. The results show that the recognizer achieves 100% top1 accuracy and 100% top5 accuracy on the val dataset,\n",
        " \n",
        "Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "## Test the trained recognizer\n",
        "\n",
        "After finetuning the recognizer, let's check the prediction results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyY3hCMwyTct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311911cc-8863-4e36-f57b-55a4c95bf882"
      },
      "source": [
        "from mmaction.apis import single_gpu_test\n",
        "from mmaction.datasets import build_dataloader\n",
        "from mmcv.parallel import MMDataParallel\n",
        "\n",
        "# Build a test dataloader\n",
        "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
        "data_loader = build_dataloader(\n",
        "        dataset,\n",
        "        videos_per_gpu=1,\n",
        "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "        dist=False,\n",
        "        shuffle=False)\n",
        "model = MMDataParallel(model, device_ids=[0])\n",
        "outputs = single_gpu_test(model, data_loader)\n",
        "\n",
        "eval_config = cfg.evaluation\n",
        "eval_config.pop('interval')\n",
        "eval_res = dataset.evaluate(outputs, **eval_config)\n",
        "for name, val in eval_res.items():\n",
        "    print(f'{name}: {val:.04f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 2.1 task/s, elapsed: 5s, ETA:     0s\n",
            "Evaluating top_k_accuracy ...\n",
            "\n",
            "top1_acc\t1.0000\n",
            "top5_acc\t1.0000\n",
            "\n",
            "Evaluating mean_class_accuracy ...\n",
            "\n",
            "mean_acc\t1.0000\n",
            "top1_acc: 1.0000\n",
            "top5_acc: 1.0000\n",
            "mean_class_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTiv1EJJKbBT"
      },
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = 'configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'tutorial_exps/epoch_30.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(cfg, checkpoint, device='cuda:0')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdCc_H6QKbBx"
      },
      "source": [
        "# Use the recognizer to do inference\n",
        "video = 'tutorial_exps/0pVGiAU6XEA.mp4'\n",
        "label = 'tutorial_exps/label_map.txt'\n",
        "results = inference_recognizer(model, video, label)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bC9ZH_qKbBy",
        "outputId": "fdbca014-427c-414f-e872-f356b8512dee"
      },
      "source": [
        "# Let's show the results\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rope climbing:  0.80804515\n",
            "blow glass:  -1.0268286\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}